---
---

@inproceedings{hclt_2024,
  abbr={HCLT},
  bibtex_show={true},
  title={Analysis of knowledge forgetting problem in Locate-Then-Edit knowledge editing method},
  author={Yeom, SiHyeong and Lee, SeongHee and Park, SeongSik and Kim, Hark-Soo},
  booktitle={Annual Conference on Human and Language Technology},
  pages={590--594},
  year={2024},
  abstract={지식 편집은 거대 언어 모델에서 잘못되었거나 오래된 지식을 수정하고 새로운 지식을 주입하기 위한 기술이다. 지식 편집의 목적은 기존 모델의 성능을 유지하면서 특정 지식만을 효율적으로 변경하는 것이다. 그 중 Locate-Then-Edit 방법은 인과 매개 분석을 수행하여 모델에서 지식이 저장된 특정 위치를 탐색하고 일부 매개변수만을 편집함으로써 효율적인 지식 편집의 가능성을 보여준다. 하지만, 이와 같은 편집 방법은 동일한 subject에 대한 연속적인 지식 편집을 수행했을 때, 이전에 편집된 지식이 망각된다는 문제가 발생한다. 본 논문에서는 이러한 동일 subject에 대한 동시 및 연속 지식 편집에서 발생하는 문제점을 구체적으로 탐구한다.},
  selected={false},
  pdf={hclt_2024.pdf}
}

@inproceedings{hclt_2025,
  abbr={HCLT},
  bibtex_show={true},
  title={Improving the Efficiency of Iterative Retrieval-Augmented Generation with an External Classifier},
  author={Yeom, Sihyeong and Jeong, Geunyeong and Lee, Seonghee and Kim, Harksoo},
  booktitle={Annual Conference on Human and Language Technology},
  pages={652--657},
  year={2025},
  month={October},
  abstract={검색 증강 생성은 질문과 관련된 정보를 검색하여 맥락으로 사용함으로써 대형 언어 모델이 학습할 때 보지 못한 질문에도 답변할 수 있게 만든다. 하지만, 일반적인 검색 증강 생성은 단 한 번의 검색과 생성을 수행하기 때문에 복잡한 질의를 효과적으로 다루는 데 한계가 존재한다. 최근 연구에서는 복잡한 질의를 하위 질의로 분해하고, 반복적으로 검색과 생성을 수행하는 학습 기반 반복적 검색 증강 생성(Iterative RAG)이 뛰어난 성능을 보여주었지만, 언어 모델의 반복 호출로 인한 높은 계산 비용이 요구된다. 이에 본 연구는 외부 분류기를 활용하여 성능을 크게 저하시키지 않으면서도, 토큰 소비량을 효과적으로 줄일 수 있는 방법을 제안한다.},
  selected={false},
  pdf={hclt_2025.pdf}
}
